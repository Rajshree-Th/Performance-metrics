{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of 5_Performance_metrics_Instructions.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rajshree-Th/Performance-metrics/blob/main/Copy_of_5_Performance_metrics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0Ej_bXyQvnV"
      },
      "source": [
        "# Compute performance metrics for the given Y and Y_score without sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CHb6NE7Qvnc"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KbsWXuDaQvnq"
      },
      "source": [
        "<pre>\n",
        "<font color='red'><b>A.</b></font> Compute performance metrics for the given data <strong>5_a.csv</strong>\n",
        "   <b>Note 1:</b> number of positive points >> number of negatives points\n",
        "   <b>Note 2:</b> to use pandas or numpy to read the data from <b>5_a.csv</b>\n",
        "   <b>Note 3:</b> to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
        "\n",
        "<pre>\n",
        "<ol>\n",
        "<li> To compute Confusion Matrix </li>\n",
        "<li> To compute F1 Score </li>\n",
        "<li> To compute AUC Score, to compute different thresholds and for each threshold computing tpr,fpr \n",
        "and then using numpy.trapz(tpr_array, fpr_array) \n",
        "<a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>, \n",
        "<a href='https://stackoverflow.com/a/39678975/4084039'\n",
        ">https://stackoverflow.com/a/39678975/4084039</a> \n",
        "Note: it should be numpy.trapz(tpr_array, fpr_array) not numpy.trapz(fpr_array, tpr_array)</li>\n",
        "<li> To compute Accuracy Score </li>\n",
        "</ol>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaFLW7oBQvnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98787f07-f37f-44a1-af3c-aa1e9ff824f6"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/gdrive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvDnwVFj-zCw"
      },
      "source": [
        "data_path = \"/gdrive/My Drive/MY_DB/Performance Metrix/5_a.csv\"\n",
        "data_a = pd.read_csv(data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmblYUcn-6gP",
        "outputId": "df95981e-9b03-4b04-b3b2-8da5018537e4"
      },
      "source": [
        "data_a.y.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0    10000\n",
              "0.0      100\n",
              "Name: y, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYmLe3MY_BeG"
      },
      "source": [
        "def predict_level(probability, thres):\n",
        "    pred = np.where(probability < thres, 0, 1)\n",
        "    return pred\n",
        "\n",
        "def confusion_matrix(actual, predicted):\n",
        "    tn, fp, fn, tp = 0, 0, 0, 0\n",
        "    tn = np.sum((actual == 0) & (predicted == 0))\n",
        "    fp = np.sum((actual == 0) & (predicted == 1))\n",
        "    fn = np.sum((actual == 1) & (predicted == 0))\n",
        "    tp = np.sum((actual == 1) & (predicted == 1))\n",
        "    return tn,fp,fn,tp\n",
        "\n",
        "def recall(tn,fp,fn,tp):\n",
        "    return tp/(tp+fn)\n",
        "\n",
        "def precision(tn,fp,fn,tp):\n",
        "    return tp/(tp+fp)\n",
        "\n",
        "def fallout(tn,fp,fn,tp):\n",
        "    return fp/(fp+tn)\n",
        "\n",
        "def f1_score(tn,fp,fn,tp):\n",
        "    re = tp/(tp+fn)\n",
        "    pr = tp/(tp+fp)\n",
        "    return 2*pr*re/(pr+re)\n",
        "    \n",
        "def roc(actual, probability, thresholds):\n",
        "    tpr = []\n",
        "    fpr = []\n",
        "    for threshold in thresholds:\n",
        "        pred = np.where(probability < threshold, 0, 1)\n",
        "        tn_t, fp_t, fn_t, tp_t = confusion_matrix(actual, pred)\n",
        "        tpr = np.append(tpr, recall(tn_t,fp_t,fn_t,tp_t))\n",
        "        fpr = np.append(fpr, fallout(tn_t,fp_t,fn_t,tp_t))\n",
        "    return (tpr, fpr)\n",
        "\n",
        "def calculate_area(tpr_list, fpr_list):\n",
        "    return np.trapz(tpr_list, fpr_list)\n",
        "    \n",
        "def calculate_accuracy(tn,fp,fn,tp):\n",
        "    return ((tn+tp)/(tn+fp+fn+tp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIssZEwy_hhJ",
        "outputId": "d08d6265-e812-47f8-f82d-1ef8b121a5f9"
      },
      "source": [
        "threshold = 0.5\n",
        "y_pred_a = predict_level(data_a.proba, threshold)\n",
        "\n",
        "TNa, FPa, FNa, TPa = confusion_matrix(data_a.y, y_pred_a)\n",
        "print(\"True Negative:\", TNa)   \n",
        "print(\"False Positive:\", FPa)\n",
        "print(\"False Negative:\", FNa)\n",
        "print(\"True Positive:\", TPa)\n",
        "\n",
        "print(\"F1 score:\", f1_score(TNa, FPa, FNa, TPa))\n",
        "\n",
        "p_score_a = np.array(data_a.proba)\n",
        "sorted_proba_a = np.sort(p_score_a)[::-1]\n",
        "\n",
        "TPRa, FPRa = roc(data_a.y, data_a.proba, sorted_proba_a)\n",
        "\n",
        "print(\"Area Under Curve:\", calculate_area(TPRa,FPRa))\n",
        "\n",
        "print(\"Accuracy:\", calculate_accuracy(TNa,FPa,FNa,TPa))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Negative: 0\n",
            "False Positive: 100\n",
            "False Negative: 0\n",
            "True Positive: 10000\n",
            "F1 score: 0.9950248756218906\n",
            "Area Under Curve: 0.48829900000000004\n",
            "Accuracy: 0.9900990099009901\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5KZem1BQvn2"
      },
      "source": [
        "<pre>\n",
        "<font color='red'><b>B.</b></font> Compute performance metrics for the given data <strong>5_b.csv</strong>\n",
        "   <b>Note 1:</b> number of positive points << number of negatives points\n",
        "   <b>Note 2:</b> to use pandas or numpy to read the data from <b>5_b.csv</b>\n",
        "   <b>Note 3:</b> need to derive the class labels from given score</pre> $y^{pred}= \\text{[0 if y_score < 0.5 else 1]}$\n",
        "\n",
        "<pre>\n",
        "<ol>\n",
        "<li> To compute Confusion Matrix </li>\n",
        "<li> To compute F1 Score </li>\n",
        "<li> To compute AUC Score, need to compute different thresholds and for each threshold to compute tpr,fpr\n",
        "and then usingnumpy.trapz(tpr_array, fpr_array)\n",
        "<a href='https://stackoverflow.com/q/53603376/4084039'>https://stackoverflow.com/q/53603376/4084039</a>,\n",
        "<a href='https://stackoverflow.com/a/39678975/4084039'>https://stackoverflow.com/a/39678975/4084039</a></li>\n",
        "<li> Compute Accuracy Score </li>\n",
        "</ol>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U2sKlq0YQvn5"
      },
      "source": [
        "# write your code\n",
        "data_path = \"/gdrive/My Drive/MY_DB/Performance Metrix/5_b.csv\"\n",
        "data_b = pd.read_csv(data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5PyStSjAXwN",
        "outputId": "438ba3e4-aa60-45db-982d-764b07d4a031"
      },
      "source": [
        "data_b.y.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    10000\n",
              "1.0      100\n",
              "Name: y, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BVoP3MPAdRM",
        "outputId": "48da13eb-fbf1-41a4-e482-d7d8f88fda5b"
      },
      "source": [
        "threshold = 0.5\n",
        "y_pred_b = predict_level(data_b.proba, threshold)\n",
        "\n",
        "TNb, FPb, FNb, TPb = confusion_matrix(data_b.y, y_pred_b)\n",
        "print(\"True Negative:\", TNb)   \n",
        "print(\"False Positive:\", FPb)\n",
        "print(\"False Negative:\", FNb)\n",
        "print(\"True Positive:\", TPb)\n",
        "\n",
        "print(\"F1 score:\", f1_score(TNb, FPb, FNb, TPb))\n",
        "\n",
        "p_score_b = np.array(data_b.proba)\n",
        "sorted_proba_b = np.sort(p_score_b)[::-1]\n",
        "\n",
        "TPRb, FPRb = roc(data_b.y, data_b.proba, sorted_proba_b)\n",
        "\n",
        "print(\"Area Under Curve:\", calculate_area(TPRb,FPRb))\n",
        "\n",
        "print(\"Accuracy score:\", calculate_accuracy(TNb,FPb,FPb,TPb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True Negative: 9761\n",
            "False Positive: 239\n",
            "False Negative: 45\n",
            "True Positive: 55\n",
            "F1 score: 0.2791878172588833\n",
            "Area Under Curve: 0.9377570000000001\n",
            "Accuracy score: 0.9535651836020983\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiPGonTzQvoB"
      },
      "source": [
        "<font color='red'><b>C.</b></font> Compute the best threshold (similarly to ROC curve computation) of probability which gives lowest values of metric <b>A</b> for the given data <strong>5_c.csv</strong>\n",
        "<br>\n",
        "\n",
        "we'll be predicting label of a data points like this: $y^{pred}= \\text{[0 if y_score < threshold  else 1]}$\n",
        "\n",
        "$ A = 500 \\times \\text{number of false negative} + 100 \\times \\text{numebr of false positive}$\n",
        "\n",
        "<pre>\n",
        "   <b>Note 1:</b> number of negative points > number of positive points\n",
        "   <b>Note 2:</b> to use pandas or numpy to read the data from <b>5_c.csv</b>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x5HIJzq1QvoE"
      },
      "source": [
        " # write your code\n",
        "data_path = \"/gdrive/My Drive/MY_DB/Performance Metrix/5_c.csv\"\n",
        "data_c = pd.read_csv(data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4BQlASxBBOU",
        "outputId": "a5403b3b-b7b9-436d-be82-ef2ea259d230"
      },
      "source": [
        "data_c.y.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    1805\n",
              "1    1047\n",
              "Name: y, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bb1ZBKmtBOuF",
        "outputId": "b2769df5-1ea7-4125-f4e7-a0d5d18133ba"
      },
      "source": [
        "def find_best_thres(actual, probability, thresholds):\n",
        "    fp_list = []\n",
        "    fn_list = []\n",
        "    a = []\n",
        "    for threshold in thresholds:\n",
        "        pred = np.where(probability < threshold, 0, 1)\n",
        "        tn_t, fp_t, fn_t, tp_t = confusion_matrix(actual, pred)\n",
        "        fn_list = np.append(fn_list, fn_t)\n",
        "        fp_list = np.append(fp_list, fp_t)\n",
        "        a = np.append(a, 500 * fn_t + 100 * fp_t)\n",
        "    lowest_a = a[np.argsort(a)[0]]\n",
        "    best_thres = thresholds[np.argsort(a)[0]]\n",
        "    return lowest_a, best_thres \n",
        "\n",
        "p_score_c = np.array(data_c.prob)\n",
        "\n",
        "lowest_A, best_threshold = find_best_thres(data_c.y, data_c.prob, p_score_c)\n",
        "print(\"Minimum A:\", lowest_A)\n",
        "print(\"Best threshold:\", best_threshold)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum A: 141000.0\n",
            "Best threshold: 0.2300390278970873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sD4CcgjXQvoL"
      },
      "source": [
        "<pre>\n",
        "<font color='red'><b>D.</b></font> Compute performance metrics(for regression) for the given data <strong>5_d.csv</strong>\n",
        "    <b>Note 2:</b> use pandas or numpy to read the data from <b>5_d.csv</b>\n",
        "    <b>Note 1:</b> <b>5_d.csv</b> will having two columns Y and predicted_Y both are real valued features\n",
        "<ol>\n",
        "<li> Compute Mean Square Error </li>\n",
        "<li> Compute MAPE: https://www.youtube.com/watch?v=ly6ztgIkUxk</li>\n",
        "<li> Compute R^2 error: https://en.wikipedia.org/wiki/Coefficient_of_determination#Definitions </li>\n",
        "</ol>\n",
        "</pre>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUlG7krZBapG"
      },
      "source": [
        "data_path = \"/gdrive/My Drive/MY_DB/Performance Metrix/5_d.csv\"\n",
        "data_d = pd.read_csv(data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aRfeicuFBe3C",
        "outputId": "88276ee3-b831-412d-e13c-1bd5f38c949b"
      },
      "source": [
        "data_d.y.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0      6435\n",
              "0.0      5717\n",
              "2.0      5317\n",
              "3.0      4032\n",
              "4.0      3226\n",
              "         ... \n",
              "440.0       1\n",
              "384.0       1\n",
              "390.0       1\n",
              "415.0       1\n",
              "367.0       1\n",
              "Name: y, Length: 395, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P13C5kyDBh_4"
      },
      "source": [
        "def calculate_mse(actual, predicted):\n",
        "    return (actual-predicted)**2\n",
        "\n",
        "def calculate_mape(actual, predicted):\n",
        "    return np.abs(predicted - actual)\n",
        "\n",
        "def tot_sum(actual, standard):\n",
        "    return (actual - standard)**2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyZaH1smBlTJ",
        "outputId": "340ec37b-f9d7-4c4e-c166-becd35c80953"
      },
      "source": [
        "sqr_error, m_mape, tot = 0, 0, 0\n",
        "midpoint = np.mean(data_d.y)\n",
        "for i in range(len(data_d)):\n",
        "    sqr_error += calculate_mse(data_d.y[i], data_d.pred[i])\n",
        "    m_mape += calculate_mape(data_d.y[i], data_d.pred[i])\n",
        "    tot += tot_sum(data_d.y[i], midpoint)\n",
        "\n",
        "mul = 100/(np.mean(data_d.y)*len(data_d.pred))\n",
        "\n",
        "print(\"Mean Square Error:\", sqr_error/len(data_d))\n",
        "print(\"Mean Absolute Percentage Error:\", m_mape*mul)\n",
        "print(\"Coefficient of determinant:\", 1-(sqr_error/tot))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Square Error: 177.16569974554707\n",
            "Mean Absolute Percentage Error: 12.91202994009687\n",
            "Coefficient of determinant: 0.9563582786990964\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2sRG9fYvB2Kg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}